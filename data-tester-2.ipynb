{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/tkinter/__init__.py\", line 1967, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/g7/8z1_10qj4276f7r_8x84bd_40000gn/T/ipykernel_33985/3548839093.py\", line 442, in on_double_click\n",
      "    column_name = self.table.model.df.columns[col_clicked]\n",
      "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "  File \"/Users/nedasmatulionis/Documents/Programming/.lab/lib/python3.12/site-packages/pandas/core/indexes/base.py\", line 5419, in __getitem__\n",
      "    disallow_ndim_indexing(result)\n",
      "  File \"/Users/nedasmatulionis/Documents/Programming/.lab/lib/python3.12/site-packages/pandas/core/indexers/utils.py\", line 341, in disallow_ndim_indexing\n",
      "    raise ValueError(\n",
      "ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import numpy as np\n",
    "import os\n",
    "from pandastable import Table, TableModel\n",
    "\n",
    "class_ion_data_path = '/Users/nedasmatulionis/Documents/Programming/christofk-lab/hek_std_model/mets_w_classes_hek_model.xlsx'\n",
    "\n",
    "# Scoring contribution of variables\n",
    "peak_area_impact = 0.4  # Positive impact\n",
    "iqr_diff_impact = 0.1  # Negative impact\n",
    "variability_impact = 0.2  # Negative impact\n",
    "outlier_impact = 0.3  # Negative impact\n",
    "\n",
    "class MetaboliteAnalysisApp(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title(\"Metabolite Standard Peak Area Analysis\")\n",
    "        self.geometry(\"1400x1800\")\n",
    "        \n",
    "        self.notebook = ttk.Notebook(self)\n",
    "        self.notebook.pack(fill='both', expand=True)\n",
    "\n",
    "        # Load stored data at initialization\n",
    "        self.stored_data = self.load_stored_data()\n",
    "\n",
    "        # Load class and ion data\n",
    "        self.class_ion_data = self.load_class_ion_data(class_ion_data_path)\n",
    "        self.create_class_ion_mappings()\n",
    "\n",
    "        self.setup_met_std_peak_area_check_ui()\n",
    "    \n",
    "    def apply_custom_theme(self, table):\n",
    "        options = {\n",
    "            'cellbackgr': '#e6e6e6',\n",
    "            'cellforegr': '#000000',\n",
    "            'rowselectedcolor': '#d9d9d9',\n",
    "            'colsselectedcolor': '#d9d9d9',\n",
    "            'grid_color': '#a6a6a6',\n",
    "            'text_color': '#000000',\n",
    "            'background_color': '#ffffff',\n",
    "            'font': ('Arial', 12),\n",
    "            'rowheight': 25,\n",
    "            'colheadercolor': '#f2f2f2',\n",
    "            'floatprecision': 2,\n",
    "            'align': 'center'\n",
    "        }\n",
    "        for key, value in options.items():\n",
    "            setattr(table, key, value)\n",
    "        table.redraw()\n",
    "\n",
    "    def set_column_widths(self, table, df):\n",
    "        \"\"\"Set column widths based on the content of the dataframe.\"\"\"\n",
    "        for col in df.columns:\n",
    "            max_len = max(df[col].astype(str).apply(len).max(), len(col)) + 2  # Add padding\n",
    "            table.columnwidths[col] = max_len * 8  # Adjust the multiplier as needed\n",
    "        table.redraw()\n",
    "\n",
    "    def setup_met_std_peak_area_check_ui(self):\n",
    "        self.tab_peak_area_check = ttk.Frame(self.notebook)\n",
    "        self.notebook.add(self.tab_peak_area_check, text='Std Peak Area Check')\n",
    "\n",
    "        self.file_path_frame_peak_area = tk.Frame(self.tab_peak_area_check)\n",
    "        self.file_path_frame_peak_area.grid(row=0, column=0, sticky='ew', pady=15)\n",
    "\n",
    "        self.file_path_entry_peak_area = tk.Entry(self.file_path_frame_peak_area)\n",
    "        self.file_path_entry_peak_area.grid(row=0, column=0, sticky='ew')\n",
    "        self.upload_button_peak_area = tk.Button(self.file_path_frame_peak_area, text=\"Upload Met Std Peak Area Data\", command=self.upload_std_peak_area_file)\n",
    "        self.upload_button_peak_area.grid(row=0, column=1, padx=5)\n",
    "\n",
    "        self.std_met_peak_area_stats = tk.Frame(self.tab_peak_area_check)\n",
    "        self.std_met_peak_area_stats.grid(row=1, column=0, sticky='nsew', pady=15)\n",
    "\n",
    "        self.table_frame = tk.Frame(self.std_met_peak_area_stats)\n",
    "        self.table_frame.grid(row=0, column=0, sticky='nsew')\n",
    "\n",
    "        # Create scrollbars\n",
    "        self.vsb = tk.Scrollbar(self.table_frame, orient=\"vertical\", command=self._on_vertical_scroll)\n",
    "        self.hsb = tk.Scrollbar(self.table_frame, orient=\"horizontal\", command=self._on_horizontal_scroll)\n",
    "\n",
    "        # Initialize pandastable with scrollbars\n",
    "        self.table = Table(self.table_frame, dataframe=pd.DataFrame(), showtoolbar=False, showstatusbar=False, editable=False)\n",
    "\n",
    "        # Attach scrollbars to the table\n",
    "        self.table.configure(yscrollcommand=self.vsb.set, xscrollcommand=self.hsb.set)\n",
    "        self.vsb.grid(row=0, column=1, sticky='ns')\n",
    "        self.hsb.grid(row=1, column=0, sticky='ew')\n",
    "\n",
    "        # Apply custom theme\n",
    "        self.apply_custom_theme(self.table)\n",
    "\n",
    "        self.table.show()\n",
    "\n",
    "        # Bind the double-click event\n",
    "        self.table.bind(\"<Double-Button-1>\", self.on_double_click)\n",
    "\n",
    "        self.class_groups = {}\n",
    "        self.ion_groups = {}\n",
    "\n",
    "        # Configure grid weights\n",
    "        self.tab_peak_area_check.grid_rowconfigure(1, weight=1)\n",
    "        self.tab_peak_area_check.grid_columnconfigure(0, weight=1)\n",
    "        self.std_met_peak_area_stats.grid_rowconfigure(0, weight=1)\n",
    "        self.std_met_peak_area_stats.grid_columnconfigure(0, weight=1)\n",
    "\n",
    "        # Summary frame\n",
    "        self.summary_frame = tk.Frame(self.tab_peak_area_check)\n",
    "        self.summary_frame.grid(row=2, column=0, sticky='ew', pady=10)\n",
    "\n",
    "\n",
    "    def _on_vertical_scroll(self, *args):\n",
    "        self.table.yview(*args)\n",
    "\n",
    "    def _on_horizontal_scroll(self, *args):\n",
    "        self.table.xview(*args)\n",
    "\n",
    "    def load_class_ion_data(self, filepath):\n",
    "        class_ion_data = pd.read_excel(filepath)\n",
    "        class_ion_data.columns = class_ion_data.columns.str.strip()\n",
    "        class_ion_data['metabolite'] = class_ion_data['metabolite'].str.replace('|', ';').str.replace('\"', '').str.strip()\n",
    "        class_ion_data['class'] = class_ion_data['class'].str.replace('\"', '').str.strip()\n",
    "        class_ion_data['ion'] = class_ion_data['ion'].str.replace('\"', '').str.strip()\n",
    "        class_ion_data.set_index('metabolite', inplace=True)\n",
    "        return class_ion_data\n",
    "\n",
    "    def create_class_ion_mappings(self):\n",
    "        self.class_mapping = self.class_ion_data['class'].to_dict()\n",
    "        self.ion_mapping = self.class_ion_data['ion'].to_dict()\n",
    "\n",
    "    def clean_dataframe_index(self, df):\n",
    "        df.index = df.index.str.replace('|', ';').str.replace('\"', '').str.strip()\n",
    "        return df\n",
    "\n",
    "\n",
    "    def get_color_tag(self, score):\n",
    "        try:\n",
    "            score = float(score)\n",
    "        except ValueError:\n",
    "            return None\n",
    "        if score > 0.5:\n",
    "            return 'lightgreen'\n",
    "        elif score < 0:\n",
    "            return 'lightcoral'\n",
    "        else:\n",
    "            return 'yellow'\n",
    "\n",
    "\n",
    "    def upload_std_peak_area_file(self):\n",
    "        analysis_fpath = filedialog.askopenfilename()\n",
    "        if not analysis_fpath:\n",
    "            return\n",
    "\n",
    "        self.file_path_entry_peak_area.delete(0, tk.END)\n",
    "        self.file_path_entry_peak_area.insert(0, analysis_fpath)\n",
    "\n",
    "        if self.is_excel_file(analysis_fpath):\n",
    "            xls = pd.ExcelFile(analysis_fpath)\n",
    "            if 'PoolAfterDF' in xls.sheet_names:\n",
    "                self.df = pd.read_excel(analysis_fpath, sheet_name='PoolAfterDF', index_col='Compound')\n",
    "                self.df = self.clean_dataframe_index(self.df)  # Clean the DataFrame index\n",
    "                self.df_normalized = self.df.div(self.df.loc['trifluoromethanesulfonate'])\n",
    "                self.update_table()\n",
    "            else:\n",
    "                messagebox.showerror(\"Error\", \"'PoolAfterDF' sheet not present in the Excel file.\")\n",
    "        else:\n",
    "            messagebox.showerror(\"Error\", \"Selected file is not a valid Excel file.\")\n",
    "\n",
    "    def is_excel_file(self, fpath):\n",
    "        return fpath.endswith(('.xls', '.xlsx'))\n",
    "    \n",
    "    def load_stored_data(self):\n",
    "        directory = os.path.expanduser('~/Documents/Programming/christofk-lab/hek_std_model/hek_model_stored')\n",
    "        stored_data = {}\n",
    "        if not os.path.exists(directory):\n",
    "            print(f\"Directory not found: {directory}\")\n",
    "            return {}  # Return an empty dictionary if the directory does not exist\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith('.xlsx'):\n",
    "                path = os.path.join(directory, file)\n",
    "                try:\n",
    "                    df_original = pd.read_excel(path, index_col='Compound')\n",
    "                    if 'trifluoromethanesulfonate' in df_original.index:\n",
    "                        df_normalized = df_original.div(df_original.loc['trifluoromethanesulfonate'])\n",
    "                        date_label = file.split('_')[0]\n",
    "                        stored_data[date_label] = (df_original, df_normalized)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to load {file}: {e}\")\n",
    "        return stored_data\n",
    "    \n",
    "    def calculate_rsd(self, data):\n",
    "        \"\"\"Calculate the Relative Standard Deviation (RSD), handling cases where the mean is zero.\"\"\"\n",
    "        mean = data.mean()\n",
    "        if mean == 0:\n",
    "            return 0  # Return 0 or some other appropriate value instead of NaN\n",
    "        return (data.std() / mean) * 100\n",
    "        \n",
    "    def calculate_iqr_and_range(self, data):\n",
    "        \"\"\"Calculates the interquartile range and min-max of the given data.\"\"\"\n",
    "        q75, q25 = np.percentile(data, [75 ,25])\n",
    "        iqr = q75 - q25\n",
    "        data_min = np.min(data)\n",
    "        data_max = np.max(data)\n",
    "        min_max_range = f\"{data_min:.2e}-{data_max:.2e}\"\n",
    "        return iqr, min_max_range\n",
    "    \n",
    "    def calculate_scores(self):\n",
    "        # Calculate scores for original and normalized data\n",
    "        original_scores = self.calculate_data_scores(self.df, normalized=False)\n",
    "        normalized_scores = self.calculate_data_scores(self.df_normalized, normalized=True)\n",
    "\n",
    "        # Normalize the scores\n",
    "        # original_scores = self.normalize_scores(original_scores)\n",
    "        # normalized_scores = self.normalize_scores(normalized_scores)\n",
    "\n",
    "        # Combine original and normalized scores into a single dictionary\n",
    "        scores = {compound: (original_scores.get(compound, 'ND'), normalized_scores.get(compound, 'ND'))\n",
    "                for compound in self.df.index}\n",
    "        return scores\n",
    "\n",
    "    def calculate_data_scores(self, df, normalized):\n",
    "        stored_means = {}\n",
    "        stored_iqrs = {}\n",
    "        internal_standard = 'trifluoromethanesulfonate'\n",
    "\n",
    "        for date_label, (df_orig, df_norm) in self.stored_data.items():\n",
    "            df_to_use = df_norm if normalized else df_orig\n",
    "            for compound in df_to_use.index:\n",
    "                if compound not in stored_means:\n",
    "                    stored_means[compound] = []\n",
    "                    stored_iqrs[compound] = []\n",
    "                values = df_to_use.loc[compound].values.flatten()\n",
    "                stored_means[compound].extend(values)\n",
    "                q75, q25 = np.percentile(values, [75, 25])\n",
    "                iqr = q75 - q25\n",
    "                stored_iqrs[compound].append(iqr)\n",
    "\n",
    "        # Calculate mean and IQR of the stored data\n",
    "        stored_means = {compound: np.mean(values) for compound, values in stored_means.items()}\n",
    "        stored_iqrs = {compound: np.mean(values) for compound, values in stored_iqrs.items()}\n",
    "\n",
    "        scores = {}\n",
    "        for compound in df.index:\n",
    "            if compound in stored_means:\n",
    "                values = df.loc[compound].values.flatten()\n",
    "                mean_peak_area = np.mean(values)\n",
    "                iqr_diff = abs(np.percentile(values, 75) - np.percentile(values, 25) - stored_iqrs[compound])\n",
    "\n",
    "                # Calculate relative measures\n",
    "                mean_peak_area_score = mean_peak_area / stored_means[compound] if stored_means[compound] != 0 else mean_peak_area\n",
    "                iqr_diff_score = iqr_diff / stored_iqrs[compound] if stored_iqrs[compound] != 0 else iqr_diff\n",
    "\n",
    "                # Internal standard adjustment for normalized data\n",
    "                if normalized and internal_standard in df.index:\n",
    "                    internal_standard_ratio = df.loc[internal_standard].mean() / self.stored_data_mean(internal_standard, normalized)\n",
    "                    mean_peak_area_score *= internal_standard_ratio\n",
    "\n",
    "                # Calculate variability impact\n",
    "                variability_impact = self.calculate_variability_impact(values)\n",
    "\n",
    "                # Detect and penalize outliers\n",
    "                outlier_impact = self.detect_outliers(values)\n",
    "\n",
    "                # Combine the scores with weights: mean positively, IQR difference negatively, variability negatively, outliers negatively\n",
    "                peak_area_contrib = mean_peak_area_score * peak_area_impact  # Positive impact\n",
    "                iqr_diff_contrib = -iqr_diff_score * iqr_diff_impact  # Negative impact\n",
    "                variability_contrib = -variability_impact * variability_impact  # Negative impact\n",
    "                outlier_contrib = -outlier_impact * outlier_impact  # Negative impact\n",
    "\n",
    "                scores[compound] = peak_area_contrib + iqr_diff_contrib + variability_contrib + outlier_contrib\n",
    "        return scores\n",
    "\n",
    "    def stored_data_mean(self, compound, normalized):\n",
    "        means = []\n",
    "        for date_label, (df_orig, df_norm) in self.stored_data.items():\n",
    "            df_to_use = df_norm if normalized else df_orig\n",
    "            if compound in df_to_use.index:\n",
    "                means.append(df_to_use.loc[compound].mean())\n",
    "        return np.mean(means) if means else 1  # Return 1 if no means found to avoid division by zero\n",
    "\n",
    "    def calculate_variability_impact(self, data):\n",
    "        # Calculate the standard deviation as a measure of variability\n",
    "        return data.std() / data.mean() if data.mean() != 0 else data.std()\n",
    "\n",
    "    def detect_outliers(self, data):\n",
    "        # Calculate the number of outliers based on IQR\n",
    "        q75, q25 = np.percentile(data, [75, 25])\n",
    "        iqr = q75 - q25\n",
    "        lower_bound = q25 - 1.5 * iqr\n",
    "        upper_bound = q75 + 1.5 * iqr\n",
    "        outliers = [x for x in data if x < lower_bound or x > upper_bound]\n",
    "        outlier_impact = len(outliers) / len(data)  # Proportion of outliers\n",
    "        return outlier_impact\n",
    "\n",
    "    def normalize_scores(self, scores):\n",
    "        min_score = min(scores.values())\n",
    "        max_score = max(scores.values())\n",
    "        range_score = max_score - min_score\n",
    "        if range_score == 0:\n",
    "            return {compound: 0.5 for compound in scores}\n",
    "        return {compound: (score - min_score) / range_score for compound, score in scores.items()}\n",
    "\n",
    "    def update_table(self, sort_by=None):\n",
    "        scores = self.calculate_scores()  # Calculate scores if scoring is applied\n",
    "\n",
    "        data = []\n",
    "        columns = [\n",
    "            'Compound', 'Class', 'Ion', 'Mean', 'min-max', 'RSD', 'IQR',\n",
    "            'N Mean', 'N min-max', 'N RSD', 'N IQR', 'Score', 'N Score'\n",
    "        ]\n",
    "\n",
    "        if sort_by == 'class':\n",
    "            sorted_compounds = sorted(self.df.index, key=lambda x: self.class_mapping.get(x.replace('|', ';').replace('\"', '').strip(), ''))\n",
    "        elif sort_by == 'ion':\n",
    "            sorted_compounds = sorted(self.df.index, key=lambda x: self.ion_mapping.get(x.replace('|', ';').replace('\"', '').strip(), ''))\n",
    "        else:\n",
    "            sorted_compounds = self.df.index\n",
    "\n",
    "        for compound in sorted_compounds:\n",
    "            original_data = self.df.loc[compound]\n",
    "            normalized_data = self.df_normalized.loc[compound]\n",
    "\n",
    "            original_rsd = self.calculate_rsd(original_data)\n",
    "            normalized_rsd = self.calculate_rsd(normalized_data)\n",
    "\n",
    "            original_iqr, original_min_max = self.calculate_iqr_and_range(original_data)\n",
    "            normalized_iqr, normalized_min_max = self.calculate_iqr_and_range(normalized_data)\n",
    "\n",
    "            score = scores[compound][0] if scores and compound in scores else \"N/A\"\n",
    "            n_score = scores[compound][1] if scores and compound in scores else \"N/A\"\n",
    "\n",
    "            values = [\n",
    "                compound.replace('\"', ''),\n",
    "                self.class_mapping.get(compound, 'N/A'),\n",
    "                self.ion_mapping.get(compound, 'N/A'),\n",
    "                f\"{original_data.mean():.3e}\",\n",
    "                original_min_max,\n",
    "                f\"{original_rsd:.2f}\",\n",
    "                f\"{original_iqr:.3e}\",\n",
    "                f\"{normalized_data.mean():.3e}\",\n",
    "                normalized_min_max,\n",
    "                f\"{normalized_rsd:.2f}\",\n",
    "                f\"{normalized_iqr:.3e}\",\n",
    "                f\"{score:.3f}\" if score != \"N/A\" else \"N/A\",\n",
    "                f\"{n_score:.3f}\" if n_score != \"N/A\" else \"N/A\"\n",
    "            ]\n",
    "            data.append(values)\n",
    "\n",
    "        df_display = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "        if self.table is None:\n",
    "            self.table = Table(self.table_frame, dataframe=df_display, showtoolbar=True, showstatusbar=True)\n",
    "            self.table.show()\n",
    "        else:\n",
    "            self.table.updateModel(TableModel(df_display))\n",
    "            self.table.redraw()\n",
    "\n",
    "        # Set column widths\n",
    "        self.set_column_widths(self.table, df_display)\n",
    "\n",
    "        # Apply color to the 'Score' and 'N Score' columns\n",
    "        self.apply_color_to_scores()\n",
    "\n",
    "        # Update summary\n",
    "        self.update_summary(df_display)\n",
    "\n",
    "\n",
    "    def apply_color_to_scores(self):\n",
    "        # Define the color function for scores\n",
    "        def color_score(value):\n",
    "            if value == \"N/A\":\n",
    "                return None\n",
    "            value = float(value)\n",
    "            if value > 0.5:\n",
    "                return \"lightgreen\"\n",
    "            elif value < 0:\n",
    "                return \"lightcoral\"\n",
    "            else:\n",
    "                return \"yellow\"\n",
    "\n",
    "        # Create a mask for the dataframe\n",
    "        mask_score = pd.Series(index=self.table.model.df.index, dtype=object)\n",
    "        mask_n_score = pd.Series(index=self.table.model.df.index, dtype=object)\n",
    "\n",
    "        for row in range(len(self.table.model.df)):\n",
    "            score_value = self.table.model.df.iloc[row]['Score']\n",
    "            n_score_value = self.table.model.df.iloc[row]['N Score']\n",
    "            \n",
    "            mask_score.iloc[row] = color_score(score_value)\n",
    "            mask_n_score.iloc[row] = color_score(n_score_value)\n",
    "\n",
    "        # Apply the color mask to the table\n",
    "        self.table.setColorByMask(col='Score', mask=mask_score.notnull(), clr=mask_score)\n",
    "        self.table.setColorByMask(col='N Score', mask=mask_n_score.notnull(), clr=mask_n_score)\n",
    "        self.table.redraw()\n",
    "\n",
    "\n",
    "    def update_summary(self, df_display):\n",
    "        # Clear existing widgets in summary frame\n",
    "        for widget in self.summary_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "        summary_text = tk.Text(self.summary_frame, height=10, wrap='word', state='normal')\n",
    "        summary_text.pack(fill='both', expand=True)\n",
    "\n",
    "        class_summary = self.calculate_summary_by_color(df_display, 'Class')\n",
    "        ion_summary = self.calculate_summary_by_color(df_display, 'Ion')\n",
    "\n",
    "        summary_text.insert(tk.END, \"Class Summary:\\n\")\n",
    "        summary_text.insert(tk.END, class_summary.to_string())\n",
    "        summary_text.insert(tk.END, \"\\n\\nIon Summary:\\n\")\n",
    "        summary_text.insert(tk.END, ion_summary.to_string())\n",
    "\n",
    "        summary_text.config(state='disabled')\n",
    "\n",
    "\n",
    "    def calculate_summary_by_color(self, df_display, group_by_column):\n",
    "        def safe_apply_color_tag(value):\n",
    "            try:\n",
    "                return self.get_color_tag(float(value))\n",
    "            except ValueError:\n",
    "                return None\n",
    "\n",
    "        summary = df_display.groupby(group_by_column)[['Score', 'N Score']].apply(\n",
    "            lambda x: pd.Series({\n",
    "                'Green Original': (x['Score'].apply(safe_apply_color_tag) == 'lightgreen').sum(),\n",
    "                'Yellow Original': (x['Score'].apply(safe_apply_color_tag) == 'yellow').sum(),\n",
    "                'Red Original': (x['Score'].apply(safe_apply_color_tag) == 'lightcoral').sum(),\n",
    "                'Green Normalized': (x['N Score'].apply(safe_apply_color_tag) == 'lightgreen').sum(),\n",
    "                'Yellow Normalized': (x['N Score'].apply(safe_apply_color_tag) == 'yellow').sum(),\n",
    "                'Red Normalized': (x['N Score'].apply(safe_apply_color_tag) == 'lightcoral').sum()\n",
    "            })\n",
    "        )\n",
    "        return summary\n",
    "\n",
    "\n",
    "    def on_double_click(self, event):\n",
    "        row_clicked = self.table.get_row_clicked(event)\n",
    "        col_clicked = self.table.get_col_clicked(event)\n",
    "        column_name = self.table.model.df.columns[col_clicked]\n",
    "        \n",
    "        compound = self.table.model.df.iloc[row_clicked]['Compound']\n",
    "        \n",
    "        if column_name in [\"Mean\", \"min-max\"]:  \n",
    "            data = self.df.loc[compound]\n",
    "            title_suffix = \"Original Replicates\"\n",
    "            self.plot_data_points_scatter(data, compound, title_suffix)\n",
    "\n",
    "        elif column_name in [\"N Mean\", \"N min-max\"]:\n",
    "            data = self.df_normalized.loc[compound]\n",
    "            title_suffix = \"Normalized Replicates\"\n",
    "            self.plot_data_points_scatter(data, compound, title_suffix)\n",
    "\n",
    "        elif column_name in [\"RSD\", \"IQR\"]:\n",
    "            data = self.df.loc[compound]\n",
    "            title_suffix = \"Original\"\n",
    "            self.plot_data_points(data, compound, title_suffix)\n",
    "\n",
    "        elif column_name in [\"N RSD\", \"N IQR\"]:\n",
    "            data = self.df_normalized.loc[compound]\n",
    "            title_suffix = \"Normalized\"\n",
    "            self.plot_data_points(data, compound, title_suffix)\n",
    "\n",
    "        elif column_name in [\"Score\", \"N Score\"]:\n",
    "            if column_name == \"Score\":\n",
    "                title_suffix = \"Original with Stored Data\"\n",
    "                normalized = False\n",
    "            else:\n",
    "                title_suffix = \"Normalized with Stored Data\"\n",
    "                normalized = True\n",
    "            self.plot_box_w_stored(compound, title_suffix, normalized)\n",
    "\n",
    "    def plot_box_w_stored(self, compound_name, title_suffix, normalized):\n",
    "        if not self.stored_data:\n",
    "            messagebox.showerror(\"Error\", \"Stored data is not available.\")\n",
    "            return\n",
    "\n",
    "        data_lists = []\n",
    "        labels = []\n",
    "\n",
    "        # Prepare data from stored files\n",
    "        stored_data_entries = []\n",
    "        for date_label, (df_orig, df_norm) in self.stored_data.items():\n",
    "            df_to_use = df_norm if normalized else df_orig\n",
    "            if compound_name in df_to_use.index:\n",
    "                data = df_to_use.loc[compound_name].values.flatten()\n",
    "                stored_data_entries.append((date_label, data))\n",
    "\n",
    "        # Sort data by date label to ensure consistent order\n",
    "        stored_data_entries.sort(key=lambda x: x[0])\n",
    "\n",
    "        # Append sorted data\n",
    "        for date_label, data in stored_data_entries:\n",
    "            data_lists.append(data)\n",
    "            labels.append(date_label)\n",
    "\n",
    "        # Add the new data last\n",
    "        if compound_name in (self.df_normalized if normalized else self.df).index:\n",
    "            current_data = (self.df_normalized if normalized else self.df).loc[compound_name].values.flatten()\n",
    "            data_lists.append(current_data)\n",
    "            labels.append('New')  # This label will appear last\n",
    "\n",
    "        # Ensure all entries in data_lists are 1D arrays\n",
    "        data_lists = [np.array(data).flatten() for data in data_lists]\n",
    "\n",
    "        # Generate plot if there is any data to show\n",
    "        if data_lists:\n",
    "            popup = tk.Toplevel()\n",
    "            popup.title(f\"{title_suffix} - {compound_name}\")\n",
    "            popup.geometry(\"1000x600\")\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.boxplot(data_lists, tick_labels=labels, notch=True, patch_artist=True)\n",
    "            ax.set_title(f\"{title_suffix} - {compound_name}\")\n",
    "            ax.set_ylabel('Normalized Peak Area Values' if normalized else 'Original Peak Area Values')\n",
    "            ax.set_xlabel('Date')\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            canvas = FigureCanvasTkAgg(fig, master=popup)\n",
    "            canvas.draw()\n",
    "            canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=True)\n",
    "            tk.Button(popup, text=\"Close\", command=popup.destroy).pack(side=tk.BOTTOM)\n",
    "        else:\n",
    "            messagebox.showinfo(\"Data Unavailable\", f\"No data available for {compound_name}.\")\n",
    "\n",
    "    def plot_data_points_scatter(self, data, compound_name, title_suffix):\n",
    "        # Create a popup window for the scatter plot\n",
    "        popup = tk.Toplevel()\n",
    "        popup.title(f\"{compound_name} - {title_suffix}\")\n",
    "        popup.geometry(\"1000x1000\")\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        # Plot data points\n",
    "        ax.scatter(range(len(data)), data, color='blue', alpha=0.7, label=f'{compound_name} data')\n",
    "        \n",
    "        # Customizing the plot\n",
    "        ax.set_title(f\"{compound_name} - {title_suffix}\")\n",
    "        ax.set_ylabel(\"Values\")\n",
    "        ax.set_xlabel(\"Sample Index\")\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "        # Creating a canvas as a matplotlib backend\n",
    "        canvas = FigureCanvasTkAgg(fig, master=popup)\n",
    "        canvas.draw()\n",
    "        canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Add a close button to the popup\n",
    "        tk.Button(popup, text=\"Close\", command=popup.destroy).pack(side=tk.BOTTOM)\n",
    "\n",
    "    def plot_data_points(self, data, compound_name, title_suffix):\n",
    "        # Prepare data by grouping by the initial part of the column name\n",
    "        groups = {}\n",
    "        for col in data.dropna().index:\n",
    "            date = col.split('-')[0]  # Assuming date is the first part before '-HEK-std'\n",
    "            if date not in groups:\n",
    "                groups[date] = []\n",
    "            groups[date].append(data[col])\n",
    "\n",
    "        # Setup the popup window\n",
    "        popup = tk.Toplevel()\n",
    "        popup.title(f\"{compound_name} - {title_suffix}\")\n",
    "        popup.geometry(\"1000x1000\")\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        # Create boxplot for each group of data\n",
    "        box_data = [groups[date] for date in sorted(groups)]\n",
    "        bp = ax.boxplot(box_data, tick_labels=sorted(groups.keys()), notch=True, vert=True, patch_artist=True, showfliers=True)\n",
    "\n",
    "        # Customize the boxplot appearance\n",
    "        for box in bp['boxes']:\n",
    "            # Set edge color and fill with a more transparent color\n",
    "            box.set(color='#1f77b4', linewidth=2)\n",
    "            box.set(facecolor='#1f77b4', alpha=0.5)  # Set transparency\n",
    "\n",
    "        for whisker in bp['whiskers']:\n",
    "            whisker.set(color='#1f77b4', linewidth=2)\n",
    "\n",
    "        for cap in bp['caps']:\n",
    "            cap.set(color='#1f77b4', linewidth=2)\n",
    "\n",
    "        for median in bp['medians']:\n",
    "            median.set(color='yellow', linewidth=2)  # Set medians to yellow for visibility\n",
    "\n",
    "        for flier in bp['fliers']:\n",
    "            flier.set(marker='o', color='#e7298a', alpha=0.9)  # Outliers visible as pink dots\n",
    "\n",
    "        # Add individual data points on the plot for clarity\n",
    "        for i, line in enumerate(groups):\n",
    "            y_data = groups[line]\n",
    "            x_data = np.random.normal(1 + i, 0.02, size=len(y_data))  # Add some jitter to the x-axis\n",
    "            ax.plot(x_data, y_data, 'r.', alpha=0.5)  # Points are plotted as red dots with transparency\n",
    "\n",
    "        ax.set_title(f\"{compound_name} - {title_suffix}\")\n",
    "        ax.set_ylabel(\"Peak Area\")\n",
    "        ax.set_xlabel(\"Date Run\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Create a canvas as a matplotlib backend\n",
    "        canvas = FigureCanvasTkAgg(fig, master=popup)\n",
    "        canvas.draw()\n",
    "        canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Add a close button to the popup\n",
    "        tk.Button(popup, text=\"Close\", command=popup.destroy).pack(side=tk.BOTTOM)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = MetaboliteAnalysisApp()\n",
    "    app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
